{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYcfqQKMNncD"
      },
      "outputs": [],
      "source": [
        "# cm = confusion_matrix(y_valid, pred_valid)\n",
        "# plt.figure(figsize=(10,6))\n",
        "# sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"Actual\")\n",
        "# # plt.show()\n",
        "# report = classification_report(y_valid, pred_valid, output_dict=True)\n",
        "# report_df = pd.DataFrame(report).T\n",
        "\n",
        "# plt.figure(figsize=(12,6))\n",
        "# sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap=\"Greens\")\n",
        "# plt.title(\"Classification Report Heatmap\")\n",
        "# plt.show()\n",
        "# # ==========================================\n",
        "# # üîµ MULTICLASS ROC CURVE (One-vs-Rest)\n",
        "# # ==========================================\n",
        "\n",
        "# y_valid_bin = label_binarize(y_valid, classes=best_model.classes_)\n",
        "# valid_probs = best_model.predict_proba(X_valid)\n",
        "\n",
        "# plt.figure(figsize=(10,7))\n",
        "\n",
        "# for i, cls in enumerate(best_model.classes_):\n",
        "#     fpr, tpr, _ = roc_curve(y_valid_bin[:, i], valid_probs[:, i])\n",
        "#     roc_auc = auc(fpr, tpr)\n",
        "#     plt.plot(fpr, tpr, label=f\"{cls} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "# plt.plot([0,1], [0,1], 'k--')  # diagonal line\n",
        "# plt.title(\"Multiclass ROC Curve\")\n",
        "# plt.xlabel(\"False Positive Rate\")\n",
        "# plt.ylabel(\"True Positive Rate\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# print(\"Validation Accuracy:\", accuracy_score(y_valid, pred_valid))\n",
        "# print(\"Macro F1:\", f1_score(y_valid, pred_valid, average='macro'))\n",
        "# print(classification_report(y_valid, pred_valid)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "df1=pd.read_csv('/kaggle/input/mse-2-ai-201-b-aiml-a/train.csv')\n",
        "df2=pd.read_csv('/kaggle/input/mse-2-ai-201-b-aiml-a/test.csv')\n",
        "df1['Class'].unique()\n",
        "df1.isnull().sum()\n",
        "print(\"\\nChecking null values...\\n\")\n",
        "nulls = df1.isnull().sum()\n",
        "\n",
        "print(nulls)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.barplot(x=nulls.index, y=nulls.values)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Null Values in Each Column\")\n",
        "plt.show()\n",
        "# üîç EDA PART 2: NUMERICAL COLUMN DISTRIBUTIONS\n",
        "# ==========================================\n",
        "print(\"\\nPlotting numeric distributions...\\n\")\n",
        "X.hist(bins=30, figsize=(12,10))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"\\nPlotting category-wise countplots...\\n\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(x='Class', data=df1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Countplot of Class\")\n",
        "plt.show()\n",
        "# num_cols = df1.select_dtypes(include=[np.number]).columns.tolist()\n",
        "# cat_cols = df1.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "# # üîç EDA PART 2: NUMERICAL COLUMN DISTRIBUTIONS\n",
        "# # ==========================================\n",
        "# print(\"\\nPlotting numeric distributions...\\n\")\n",
        "# X[num_cols].hist(bins=30, figsize=(12,10))\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "# # üîç EDA PART 3: CATEGORY-WISE DISTRIBUTION (COUNT PLOTS)\n",
        "# # ==========================================\n",
        "# print(\"\\nPlotting category-wise countplots...\\n\")\n",
        "# for col in cat_cols:\n",
        "#     plt.figure(figsize=(8,4))\n",
        "#     sns.countplot(data=df1, x=col)\n",
        "#     plt.xticks(rotation=45)\n",
        "#     plt.title(f\"Countplot of {col}\")\n",
        "#     plt.show()\n",
        "# print(\"\\nPlotting numeric outliers (boxplots)...\\n\")\n",
        "# for col in num_cols:\n",
        "#     plt.figure(figsize=(6,4))\n",
        "#     sns.boxplot(x=X[col])\n",
        "#     plt.title(f\"Outlier Boxplot for {col}\")\n",
        "#     plt.show()\n",
        "y=df1[\"Class\"]\n",
        "y=y.map({\"A\":0,\"B\":1})\n",
        "y=y.fillna(y.median())\n",
        "X = df1.drop([\"Class\"],axis = 1)\n",
        "X.head()\n",
        "X = X.fillna(X.mean(numeric_only = True))\n",
        "X.info()\n",
        "X.isnull().sum()\n",
        "def cap_outliers(df,cols,l=1,u = 99):\n",
        "    for col in cols:\n",
        "        lv = df[col].quantile(l/100)\n",
        "        uv = df[col].quantile(u/100)\n",
        "        df[col] = df[col].clip(lv,uv)\n",
        "    return df\n",
        "num_cols = X.select_dtypes(include = [\"float64\"]).columns\n",
        "X = cap_outliers(X,num_cols)\n",
        "cat_col = \"Class\"\n",
        "for col in num_cols:\n",
        "    plt.figure(figsize = (6,4))\n",
        "    sns.boxplot(x = cat_col,y = col,data = df1)\n",
        "sns.heatmap(X.corr())\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42,stratify = y)\n",
        "X_train.head()\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": [200, 400, 600, 800],\n",
        "    \"max_depth\": [None, 10, 20, 25],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "random_cv = RandomizedSearchCV(\n",
        "    rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=25,\n",
        "    cv=cv,\n",
        "    scoring=\"f1_macro\",\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining RandomForest...\")\n",
        "random_cv.fit(X_train, y_train)\n",
        "\n",
        "best_model = random_cv.best_estimator_\n",
        "print(\"\\nBest Parameters:\", random_cv.best_params_)\n",
        "print(\"=\"*70)\n",
        "y_p = best_model.predict(X_test)\n",
        "a = accuracy_score(y_test,y_p)\n",
        "a\n",
        "test_ids = df2[\"id\"]\n",
        "x_test = df2.drop([\"id\"],axis = 1)\n",
        "y_pred_f = best_model.predict(x_test)\n",
        "y_pred_df = pd.DataFrame(y_pred_f)\n",
        "y_pred_df\n",
        "y_pred1 = y_pred_df[0].map({0.0:\"A\",1.0:\"B\"})\n",
        "y_pred1\n",
        "submission = pd.DataFrame({\n",
        "    \"id\" : test_ids,\n",
        "    \"Class\" : y_pred1\n",
        "})\n",
        "submission.to_csv(\"aaaaaaaaaaaaaaaaaa.csv\",index = False)\n",
        "submission.head()\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}